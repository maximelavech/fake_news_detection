{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "<center> <h2> Benchmark Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "In this section, we train and evaluate a benchmark. We will fit a simple Naive Bayes Estimator to provide a baseline for comparison. Due to SageMaker's notebook limit instances, parts of this notebook had to be run on a local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import os, random, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/cleandata/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>True</td>\n",
       "      <td>budget fight loom republican flip fiscal scrip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>True</td>\n",
       "      <td>military accept transgender recruit monday pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>True</td>\n",
       "      <td>senior republican senator let mr mueller job w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>True</td>\n",
       "      <td>fbi russia probe helped australian diplomat ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>True</td>\n",
       "      <td>trump want postal service charge much amazon s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text label  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  True   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  True   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  True   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  True   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  True   \n",
       "\n",
       "                                           processed  \n",
       "0  budget fight loom republican flip fiscal scrip...  \n",
       "1  military accept transgender recruit monday pen...  \n",
       "2  senior republican senator let mr mueller job w...  \n",
       "3  fbi russia probe helped australian diplomat ti...  \n",
       "4  trump want postal service charge much amazon s...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Transform label to numeric\n",
    "# Just in case the word 'label' appears in the dataset & see below\n",
    "data['y_label'] = data['label'].apply(lambda x : ('True'==x)*1)\n",
    "del data['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "source": [
    "## I. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from utils.utils_metadata import get_structure\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true,
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "def get_frequencies(data):\n",
    "    \"\"\"\n",
    "    Returns a Counter Object where key = word and value = count\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    data (pandas.DataFrame) must have column processed where each cell are tokens joint in single string\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    count (Counter)\n",
    "    \"\"\"\n",
    "    count = Counter()\n",
    "    for sentence in data['processed']:\n",
    "        words = sentence.split()\n",
    "        count.update(words)\n",
    "    return count\n",
    "\n",
    "def extract_vocabulary(data, size = 5000, shift = 0):\n",
    "    \"\"\"\n",
    "    Returns a dictionary which maps a word to an identification integer\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    data (pandas.DataFrame) must have column processed where each cell are tokens joint in single string\n",
    "    size (int) size of vocabulary. Default = 5000\n",
    "    shift (int) start. Default = 0\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    vocabulary (dict)\n",
    "    \"\"\"    \n",
    "    vocabulary = {}\n",
    "    count = get_frequencies(data)\n",
    "    for i,word in enumerate([key for key,value in count.most_common(size)]):\n",
    "        vocabulary[word] = i + shift\n",
    "    return vocabulary\n",
    "\n",
    "def get_indices(N, proportion = [0.8,0.1,0.1], seed = 1):\n",
    "    \"\"\"\n",
    "    Returns three lists of indices\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    N (int) the size of the dataset\n",
    "    proportion (list) list of three values which should sum to 1\n",
    "    seed (int) the seed for random selection\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    three lists indtrain, indval and indtest\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.choice(np.arange(N),replace=False,size=N)\n",
    "    ind1 = int(proportion[0]*N)\n",
    "    ind2 = int(proportion[0]*N) + int(proportion[1]*N)\n",
    "    return indices[:ind1], indices[ind1:ind2], indices[ind2:]\n",
    "\n",
    "def normalize(data, fixed, estimator = None):\n",
    "    \"\"\"\n",
    "    Returns either the normalized data if the estimator != None. Otherwise, the normalization estimator.\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    data (pandas.DataFrame) a dataframe to fit or to transform \n",
    "    fixed (list) list of columns to not transform\n",
    "    estimator (trained estimator) if None, the function will fit an estimator and return it\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    Either a transformed dataframe or a trained estimator\n",
    "    \"\"\"\n",
    "    features = [column for column in data.columns if column not in fixed]\n",
    "    if estimator == None:\n",
    "        # fit and return estimator\n",
    "        norm = MinMaxScaler()\n",
    "        norm.fit(data[features].values)\n",
    "        return norm\n",
    "    else:\n",
    "        data = data.copy()\n",
    "        data[features] = estimator.transform(data[features].values)\n",
    "        return data\n",
    "\n",
    "def build_benchmark_data(data, size = 5000):\n",
    "    \"\"\"\n",
    "    Returns the training, validation and test sets and a set of model artifacts\n",
    "    \n",
    "    Input\n",
    "    -----\n",
    "    data (pandas.DataFrame) the data with the processed column\n",
    "    size (int) size of the vocabulary\n",
    "    \n",
    "    Output\n",
    "    ------\n",
    "    (x_train,y_train) , (x_val,y_val) , (x_test,y_test) : (tuple) features,labels\n",
    "    \n",
    "    AND\n",
    "    \n",
    "    artifacts : (dict) with the training, validation and test indices ; tf-idf estimator ; vocabulary\n",
    "    \"\"\"\n",
    "    indtrain, indval, indtest = get_indices(len(data))\n",
    "    Xtrain = data.loc[indtrain] ; Xvalidation = data.loc[indval] ; Xtest = data.loc[indtest]\n",
    "    vocabulary = extract_vocabulary(Xtrain, size)\n",
    "    tfidf = TfidfVectorizer(preprocessor = lambda x:x, tokenizer = lambda x:x.split(), vocabulary = vocabulary)\n",
    "    \n",
    "    # Fit on train and transform for validation and test\n",
    "    wordtrain = pd.DataFrame(tfidf.fit_transform(Xtrain['processed']).toarray(),columns =tfidf.vocabulary_)\n",
    "    wordval = pd.DataFrame(tfidf.transform(Xvalidation['processed']).toarray(),columns = tfidf.vocabulary_)\n",
    "    wordtest = pd.DataFrame(tfidf.transform(Xtest['processed']).toarray(),columns = tfidf.vocabulary_)\n",
    "    \n",
    "    # get_structure\n",
    "    Xtrain = get_structure(Xtrain).reset_index(drop=True)\n",
    "    Xvalidation = get_structure(Xvalidation).reset_index(drop=True)\n",
    "    Xtest = get_structure(Xtest).reset_index(drop=True)\n",
    "    \n",
    "    # normalize structure by fitting on train \n",
    "    fixed = ['title','text','y_label','processed']\n",
    "    estimator = normalize(Xtrain, fixed = fixed, estimator = None)\n",
    "    Xtrain = normalize(Xtrain, fixed = fixed, estimator = estimator).reset_index(drop=True)\n",
    "    Xvalidation = normalize(Xvalidation, fixed = fixed, estimator = estimator).reset_index(drop=True)\n",
    "    Xtest = normalize(Xtest, fixed = fixed, estimator = estimator).reset_index(drop=True)\n",
    "    \n",
    "    # dataframes\n",
    "    train = pd.concat([Xtrain,wordtrain],axis =1)\n",
    "    val = pd.concat([Xvalidation,wordval], axis = 1)\n",
    "    test = pd.concat([Xtest,wordtest],axis = 1)\n",
    "    features = [column for column in train.columns if column not in fixed]\n",
    "    \n",
    "    # artifacts for future use and comparison\n",
    "    artifacts = {'indtrain':indtrain,\n",
    "                 'indval':indval,\n",
    "                 'indtest':indtest,\n",
    "                 'tfidf-estimator':tfidf,\n",
    "                 'vocabulary':vocabulary}\n",
    "    \n",
    "    return (train[features],train['y_label']),(val[features],val['y_label']),(test[features],test['y_label']),artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "(x_train,y_train),(x_val,y_val),(x_test,y_test), artifacts = build_benchmark_data(data, size = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train has shape (35918, 5008) ; y_train has shape (35918,)\n",
      "x_validation has shape (4489, 5008) ; y_validation has shape (4489,)\n",
      "x_test has shape (4491, 5008) ; y_test has shape (4491,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train has shape {} ; y_train has shape {}'.format(x_train.shape,y_train.shape))\n",
    "print('x_validation has shape {} ; y_validation has shape {}'.format(x_val.shape,y_val.shape))\n",
    "print('x_test has shape {} ; y_test has shape {}'.format(x_test.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_uppercase</th>\n",
       "      <th>text_lowercase</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>text_uppercase_count</th>\n",
       "      <th>count_(?)</th>\n",
       "      <th>count_(!)</th>\n",
       "      <th>count_(#)</th>\n",
       "      <th>count_(@)</th>\n",
       "      <th>count_(-)</th>\n",
       "      <th>...</th>\n",
       "      <th>homeless</th>\n",
       "      <th>discriminate</th>\n",
       "      <th>semi</th>\n",
       "      <th>dyer</th>\n",
       "      <th>restructuring</th>\n",
       "      <th>prohibited</th>\n",
       "      <th>coordinate</th>\n",
       "      <th>centrist</th>\n",
       "      <th>sway</th>\n",
       "      <th>espionage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.158672</td>\n",
       "      <td>0.115477</td>\n",
       "      <td>0.940106</td>\n",
       "      <td>0.153331</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.313653</td>\n",
       "      <td>0.256744</td>\n",
       "      <td>0.968710</td>\n",
       "      <td>0.132240</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.177122</td>\n",
       "      <td>0.053156</td>\n",
       "      <td>0.903456</td>\n",
       "      <td>0.115665</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.199262</td>\n",
       "      <td>0.064712</td>\n",
       "      <td>0.910928</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.553506</td>\n",
       "      <td>0.270613</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.108379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5008 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_length  title_uppercase  text_lowercase  avg_sent_length  \\\n",
       "0      0.158672         0.115477        0.940106         0.153331   \n",
       "1      0.313653         0.256744        0.968710         0.132240   \n",
       "2      0.177122         0.053156        0.903456         0.115665   \n",
       "3      0.199262         0.064712        0.910928         0.110200   \n",
       "4      0.553506         0.270613        0.939394         0.108379   \n",
       "\n",
       "   text_uppercase_count  count_(?)  count_(!)  count_(#)  count_(@)  \\\n",
       "0              0.009709   0.000000        0.0        0.0        0.0   \n",
       "1              0.006472   0.000000        0.0        0.0        0.0   \n",
       "2              0.038835   0.010638        0.0        0.0        0.0   \n",
       "3              0.009709   0.000000        0.0        0.0        0.0   \n",
       "4              0.000000   0.000000        0.0        0.0        0.0   \n",
       "\n",
       "   count_(-)    ...      homeless  discriminate  semi  dyer  restructuring  \\\n",
       "0   0.009852    ...           0.0           0.0   0.0   0.0            0.0   \n",
       "1   0.000000    ...           0.0           0.0   0.0   0.0            0.0   \n",
       "2   0.014778    ...           0.0           0.0   0.0   0.0            0.0   \n",
       "3   0.004926    ...           0.0           0.0   0.0   0.0            0.0   \n",
       "4   0.000000    ...           0.0           0.0   0.0   0.0            0.0   \n",
       "\n",
       "   prohibited  coordinate  centrist  sway  espionage  \n",
       "0         0.0         0.0       0.0   0.0        0.0  \n",
       "1         0.0         0.0       0.0   0.0        0.0  \n",
       "2         0.0         0.0       0.0   0.0        0.0  \n",
       "3         0.0         0.0       0.0   0.0        0.0  \n",
       "4         0.0         0.0       0.0   0.0        0.0  \n",
       "\n",
       "[5 rows x 5008 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of zeros to all :  0.521493401637\n"
     ]
    }
   ],
   "source": [
    "zeros = sum(y_train == 0)\n",
    "ones = sum(y_train == 1)\n",
    "print('ratio of zeros to all : ',zeros/(ones+zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of zeros to all :  0.525952327913\n"
     ]
    }
   ],
   "source": [
    "zeros = sum(y_val == 0)\n",
    "ones = sum(y_val == 1)\n",
    "print('ratio of zeros to all : ',zeros/(ones+zeros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio of zeros to all :  0.531952794478\n"
     ]
    }
   ],
   "source": [
    "zeros = sum(y_test == 0)\n",
    "ones = sum(y_test == 1)\n",
    "print('ratio of zeros to all : ',zeros/(ones+zeros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets are balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes : NB(Struct + BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = GaussianNB()\n",
    "clf1.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_results(ytrue,pred):\n",
    "    accuracy = accuracy_score(ytrue,pred)\n",
    "    precision = precision_score(ytrue,pred)\n",
    "    print('accuracy:',accuracy)\n",
    "    print('precision:',precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predtrain = clf1.predict(x_train)\n",
    "predval = clf1.predict(x_val)\n",
    "predtest = clf1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.933570911521\n",
      "precision: 0.951387618176\n"
     ]
    }
   ],
   "source": [
    "get_results(y_train,predtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.931833370461\n",
      "precision: 0.951437066402\n"
     ]
    }
   ],
   "source": [
    "get_results(y_val,predval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.921843687375\n",
      "precision: 0.934491315136\n"
     ]
    }
   ],
   "source": [
    "get_results(y_test,predtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test,prediction).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative count : 1295\n",
      "False negative count : 1100\n",
      "True positive count : 1002\n",
      "False positive count : 1094\n"
     ]
    }
   ],
   "source": [
    "print('True negative count :',tn)\n",
    "print('False negative count :',fn)\n",
    "print('True positive count :',tp)\n",
    "print('False positive count :',fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes : NB(BOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow_shift = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>digit_token</th>\n",
       "      <th>trump</th>\n",
       "      <th>said</th>\n",
       "      <th>state</th>\n",
       "      <th>president</th>\n",
       "      <th>would</th>\n",
       "      <th>people</th>\n",
       "      <th>year</th>\n",
       "      <th>republican</th>\n",
       "      <th>one</th>\n",
       "      <th>...</th>\n",
       "      <th>homeless</th>\n",
       "      <th>discriminate</th>\n",
       "      <th>semi</th>\n",
       "      <th>dyer</th>\n",
       "      <th>restructuring</th>\n",
       "      <th>prohibited</th>\n",
       "      <th>coordinate</th>\n",
       "      <th>centrist</th>\n",
       "      <th>sway</th>\n",
       "      <th>espionage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040589</td>\n",
       "      <td>0.037359</td>\n",
       "      <td>0.101937</td>\n",
       "      <td>0.076857</td>\n",
       "      <td>0.054462</td>\n",
       "      <td>0.055709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109916</td>\n",
       "      <td>0.028563</td>\n",
       "      <td>0.037687</td>\n",
       "      <td>0.071215</td>\n",
       "      <td>0.072845</td>\n",
       "      <td>0.040068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125568</td>\n",
       "      <td>0.123832</td>\n",
       "      <td>0.019308</td>\n",
       "      <td>0.050950</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.098482</td>\n",
       "      <td>0.027084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038559</td>\n",
       "      <td>0.050877</td>\n",
       "      <td>0.048069</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054090</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.046693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4998 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   digit_token     trump      said     state  president     would    people  \\\n",
       "0     0.040589  0.037359  0.101937  0.076857   0.054462  0.055709  0.000000   \n",
       "1     0.000000  0.109916  0.028563  0.037687   0.071215  0.072845  0.040068   \n",
       "2     0.125568  0.123832  0.019308  0.050950   0.000000  0.098482  0.027084   \n",
       "3     0.000000  0.000000  0.038559  0.050877   0.048069  0.000000  0.054090   \n",
       "4     0.046693  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "\n",
       "   year  republican  one    ...      homeless  discriminate  semi  dyer  \\\n",
       "0   0.0    0.000000  0.0    ...           0.0           0.0   0.0   0.0   \n",
       "1   0.0    0.000000  0.0    ...           0.0           0.0   0.0   0.0   \n",
       "2   0.0    0.097095  0.0    ...           0.0           0.0   0.0   0.0   \n",
       "3   0.0    0.000000  0.0    ...           0.0           0.0   0.0   0.0   \n",
       "4   0.0    0.000000  0.0    ...           0.0           0.0   0.0   0.0   \n",
       "\n",
       "   restructuring  prohibited  coordinate  centrist  sway  espionage  \n",
       "0            0.0         0.0         0.0       0.0   0.0        0.0  \n",
       "1            0.0         0.0         0.0       0.0   0.0        0.0  \n",
       "2            0.0         0.0         0.0       0.0   0.0        0.0  \n",
       "3            0.0         0.0         0.0       0.0   0.0        0.0  \n",
       "4            0.0         0.0         0.0       0.0   0.0        0.0  \n",
       "\n",
       "[5 rows x 4998 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.iloc[:,bow_shift:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = GaussianNB()\n",
    "clf2.fit(x_train.iloc[:,bow_shift:],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "predtrain2 = clf2.predict(x_train.iloc[:,bow_shift:])\n",
    "predval2 = clf2.predict(x_val.iloc[:,bow_shift:])\n",
    "predtest2 = clf2.predict(x_test.iloc[:,bow_shift:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.931065204076\n",
      "precision: 0.947605428102\n"
     ]
    }
   ],
   "source": [
    "get_results(y_train,predtrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.92760080196\n",
      "precision: 0.943433349729\n"
     ]
    }
   ],
   "source": [
    "get_results(y_val,predval2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.919839679359\n",
      "precision: 0.932472691162\n"
     ]
    }
   ],
   "source": [
    "get_results(y_test,predtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tn2, fp2, fn2, tp2 = confusion_matrix(y_test,predtest2).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True negative count : 2253\n",
      "False negative count : 224\n",
      "True positive count : 1878\n",
      "False positive count : 136\n"
     ]
    }
   ],
   "source": [
    "print('True negative count :',tn2)\n",
    "print('False negative count :',fn2)\n",
    "print('True positive count :',tp2)\n",
    "print('False positive count :',fp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes : NB(Struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_length</th>\n",
       "      <th>title_uppercase</th>\n",
       "      <th>text_lowercase</th>\n",
       "      <th>avg_sent_length</th>\n",
       "      <th>text_uppercase_count</th>\n",
       "      <th>count_(?)</th>\n",
       "      <th>count_(!)</th>\n",
       "      <th>count_(#)</th>\n",
       "      <th>count_(@)</th>\n",
       "      <th>count_(-)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.158672</td>\n",
       "      <td>0.115477</td>\n",
       "      <td>0.940106</td>\n",
       "      <td>0.153331</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.313653</td>\n",
       "      <td>0.256744</td>\n",
       "      <td>0.968710</td>\n",
       "      <td>0.132240</td>\n",
       "      <td>0.006472</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.177122</td>\n",
       "      <td>0.053156</td>\n",
       "      <td>0.903456</td>\n",
       "      <td>0.115665</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.199262</td>\n",
       "      <td>0.064712</td>\n",
       "      <td>0.910928</td>\n",
       "      <td>0.110200</td>\n",
       "      <td>0.009709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.553506</td>\n",
       "      <td>0.270613</td>\n",
       "      <td>0.939394</td>\n",
       "      <td>0.108379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   title_length  title_uppercase  text_lowercase  avg_sent_length  \\\n",
       "0      0.158672         0.115477        0.940106         0.153331   \n",
       "1      0.313653         0.256744        0.968710         0.132240   \n",
       "2      0.177122         0.053156        0.903456         0.115665   \n",
       "3      0.199262         0.064712        0.910928         0.110200   \n",
       "4      0.553506         0.270613        0.939394         0.108379   \n",
       "\n",
       "   text_uppercase_count  count_(?)  count_(!)  count_(#)  count_(@)  count_(-)  \n",
       "0              0.009709   0.000000        0.0        0.0        0.0   0.009852  \n",
       "1              0.006472   0.000000        0.0        0.0        0.0   0.000000  \n",
       "2              0.038835   0.010638        0.0        0.0        0.0   0.014778  \n",
       "3              0.009709   0.000000        0.0        0.0        0.0   0.004926  \n",
       "4              0.000000   0.000000        0.0        0.0        0.0   0.000000  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.iloc[:,:bow_shift].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3 = GaussianNB()\n",
    "clf3.fit(x_train.iloc[:,:bow_shift],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predtrain3 = clf3.predict(x_train.iloc[:,:bow_shift])\n",
    "predval3 = clf3.predict(x_val.iloc[:,:bow_shift])\n",
    "predtest3 = clf3.predict(x_test.iloc[:,:bow_shift])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.948549473801\n",
      "precision: 0.919533942345\n"
     ]
    }
   ],
   "source": [
    "get_results(y_train,predtrain3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.954778347071\n",
      "precision: 0.926829268293\n"
     ]
    }
   ],
   "source": [
    "get_results(y_val,predval3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.947673124026\n",
      "precision: 0.916183682568\n"
     ]
    }
   ],
   "source": [
    "get_results(y_test,predtest3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Saving the data & other artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['indtrain', 'indval', 'indtest', 'tfidf-estimator', 'vocabulary'])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can't pickle lambda functions...\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def tokenizetmp(x):\n",
    "    return x.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function identity at 0x7f08d6a24598>,\n",
       "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<function tokenizetmp at 0x7f08d6a24d08>, use_idf=True,\n",
       "        vocabulary={'digit_token': 0, 'trump': 1, 'said': 2, 'state': 3, 'president': 4, 'would': 5, 'people': 6, 'year': 7, 'republican': 8, 'one': 9, 'new': 10, 'also': 11, 'obama': 12, 'clinton': 13, 'government': 14, 'house': 15, 'say': 16, 'reuters': 17, 'time': 18, 'donald': 19, 'reference_token': 20,...g': 4994, 'prohibited': 4995, 'coordinate': 4996, 'centrist': 4997, 'sway': 4998, 'espionage': 4999})"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artifacts['tfidf-estimator'].set_params(**{'preprocessor':identity,'tokenizer':tokenizetmp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/benchmark_artifacts.pickle', 'wb') as handle:\n",
    "    pickle.dump(artifacts, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing pickling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/benchmark_artifacts.pickle', 'rb') as handle:\n",
    "    testpickle = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['indtrain', 'indval', 'indtest', 'tfidf-estimator', 'vocabulary'])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpickle.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4528, 31727, 10937, 13470, 40814, 12702,  2736, 31730, 42479, 26780])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpickle['indtrain'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 265 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpickle['tfidf-estimator'].transform([data.loc[0,'processed']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "conda_amazonei_mxnet_p36",
   "language": "python",
   "name": "conda_amazonei_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
